{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Vertex AI Experiments: Autologging\n",
        "\n",
        "<table align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/autologging.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/autologging.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/experiments/autologging.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
        "      Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24743cf4a1e1"
      },
      "source": [
        "**_NOTE_**: This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "As part of the data science team, you want to try different modeling approaches during experimentation phase.To guarantee reproducibility, each approach has different parameters that you need to manually track This is a time consuming task. To address this challenge, Vertex AI SDK introduces autologging, a one-line code SDK capability which leverages MLflow to provide automatic metrics and parameters tracking associated with your  Vertex AI Experiments and experiment runs. Learn more about [Autologging data to an experiment run](https://cloud.google.com/vertex-ai/docs/experiments/autolog-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to use `Vertex AI Autologging`.\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services and resources:\n",
        "\n",
        "- Vertex AI Experiments\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Enable autologging in the Vertex AI SDK.\n",
        "- Train scikit-learn model and see the resulting experiment run with metrics and parameters autologged to Vertex AI Experiments without setting an experiment run.\n",
        "- Train Tensorflow model, check autologged metrics and parameters to Vertex AI Experiments by manually setting an experiment run with `aiplatform.start_run()` and `aiplatform.end_run()`.\n",
        "- Disable autologging in the Vertex AI SDK, train a PyTorch model and check that none of the parameters or metrics are logged.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset is the [UCI Car Evaluation dataset](https://archive-beta.ics.uci.edu/dataset/19/car+evaluation), which is derived from simple hierarchical decision model and it contains attributions to predict car evaluation class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI Experiments\n",
        "* Vertex AI Tensorboard\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2b4ef9b72d43",
        "outputId": "d0ae75bb-f97c-45c7-9ca5-8f5ba1539a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.24.0-py2.py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (1.22.2)\n",
            "Collecting shapely<2.0.0\n",
            "  Downloading Shapely-1.8.5.post1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (3.9.0)\n",
            "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
            "  Downloading google_cloud_resource_manager-1.10.0-py2.py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (2.11.0)\n",
            "Collecting packaging<22.0.0dev,>=14.3\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.59.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
            "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform) (3.0.9)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: shapely, packaging, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-aiplatform\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.0.1\n",
            "    Uninstalling shapely-2.0.1:\n",
            "      Successfully uninstalled shapely-2.0.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "Successfully installed google-cloud-aiplatform-1.24.0 google-cloud-resource-manager-1.10.0 grpc-google-iam-v1-0.12.6 packaging-21.3 shapely-1.8.5.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "packaging"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.9/dist-packages (0.6.0)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlflow\n",
            "  Downloading mlflow-2.3.0-py3-none-any.whl (17.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchdata) (2.27.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata) (1.26.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.9/dist-packages (from mlflow) (0.4)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic!=1.10.0,<2\n",
            "  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.9/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (6.4.1)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (2.2.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.9/dist-packages (from mlflow) (6.0)\n",
            "Collecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.6.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (8.1.3)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (0.4.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (2.0.9)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: pyarrow<12,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (9.0.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask<3->mlflow) (2.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from Flask<3->mlflow) (2.2.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.9/dist-packages (from gunicorn<21->mlflow) (67.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (1.0.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.6-py3-none-any.whl size=143237 sha256=bab555f229e50d5daf5d477692636998ecb9c089f1c737868ba1da56519b0677\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/d9/cb/1cdc0826334cb600957db0b5a8448db02a8995daeab2556745\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: smmap, querystring-parser, pyjwt, Mako, gunicorn, pandas, gitdb, docker, databricks-cli, alembic, gitpython, mlflow, category_encoders, torchmetrics\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.2.4 alembic-1.10.3 category_encoders-2.6.0 databricks-cli-0.17.6 docker-6.0.1 gitdb-4.0.10 gitpython-3.1.31 gunicorn-20.1.0 mlflow-2.3.0 pandas-2.0.0 pyjwt-2.6.0 querystring-parser-1.2.4 smmap-5.0.0 torchmetrics-0.11.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.9/dist-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# Install the packages\n",
        "USER = \"\"\n",
        "! pip3 install {USER} --upgrade google-cloud-aiplatform tensorflow\n",
        "! pip3 install {USER} --upgrade pandas scikit-learn category_encoders torch torchdata torchmetrics mlflow\n",
        "! pip3 install {USER} --upgrade protobuf==3.20.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f200f10a1da3",
        "outputId": "b0d5f4d1-14dd-4d4e-a68d-db13e1a5379f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oM1iC_MfAts1",
        "outputId": "3491d96f-c40b-41d9-d4e9-020e98ea312c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"gbk-poc-datamvp-poc1\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jWz5v12n3jb3"
      },
      "outputs": [],
      "source": [
        "REGION = \"europe-west4\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06571eb4063b"
      },
      "source": [
        "#### UUID\n",
        "\n",
        "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "697568e92bd6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "\n",
        "# Generate a uuid of length 8\n",
        "def generate_uuid():\n",
        "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
        "\n",
        "\n",
        "UUID = generate_uuid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**3. Colab, uncomment and run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = \"gs://bk-poc-datamvp-poc1-elenamatay\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NIq7R4HZCfIc",
        "outputId": "cb526f78-49c4-41bb-eec6-df103d29ff3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://bk-poc-datamvp-poc1-elenamatay/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'bk-poc-datamvp-poc1-elenamatay' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmXN14--y9xU"
      },
      "source": [
        "### Set up project template\n",
        "\n",
        "Set the folder you use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ohz3wHe4zFNb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "tutorial_path = os.path.join(os.getcwd(), \"sdk_autologging_tutorial\")\n",
        "data_path = os.path.join(tutorial_path, \"data\")\n",
        "\n",
        "for path in tutorial_path, data_path:\n",
        "    os.makedirs(path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dAKzp-i1UJX"
      },
      "source": [
        "### Download dataset\n",
        "\n",
        "Download the car evaluation dataset from the public Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9Ukztj7v1XZw"
      },
      "outputs": [],
      "source": [
        "from urllib import request\n",
        "\n",
        "DATA_URL = \"http://cloud-samples-data.storage.googleapis.com/vertex-ai/dataset-management/datasets/uci_car_eval/car_evaluation_preprocessed.csv\"\n",
        "data_filepath = os.path.join(data_path, \"car_evaluation_data.csv\")\n",
        "request.urlretrieve(DATA_URL, data_filepath)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "COLUMN_NAMES = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
        "df = pd.read_csv(data_filepath)\n",
        "df[\"class\"] = df[\"class\"].replace({\"unacc\": 0, \"acc\": 0, \"good\": 1, \"vgood\": 1})\n",
        "\n",
        "processed_data_filepath = os.path.join(data_path, \"car_evaluation_preprocessed.csv\")\n",
        "df.to_csv(processed_data_filepath, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BFjBFK5a3f4b",
        "outputId": "791b4a90-fe3e-4df8-b21a-fc7367cc01b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buying,maint,doors,persons,lug_boot,safety,class\n",
            "vhigh,vhigh,2,2,small,low,0\n",
            "vhigh,vhigh,2,2,small,med,0\n",
            "vhigh,vhigh,2,2,small,high,0\n",
            "vhigh,vhigh,2,2,med,low,0\n"
          ]
        }
      ],
      "source": [
        "!head {processed_data_filepath} -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Import the Vertex AI SDK to log experiments in Vertex AI Experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform as vertex_ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mwQMym-Rteu"
      },
      "source": [
        "### Helper functions\n",
        "\n",
        "To run experiments it is not uncommon to define experiment helpers, one per each modelling approach you plan to evaluate. Below you define the following experiment helpers:\n",
        "\n",
        "*   `train_sklearn_model`: A helper function to train a Decision Tree model using Sklearn.\n",
        "*   `train_tensorflow_model`: A helper function to train a simple model using Tensorflow.\n",
        "*   `train_pytorch_model`: A helper function to train a simple neural network using PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T5tWyGgeRvXC"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    A function to set the seed for reproducibility.\n",
        "    Args:\n",
        "        seed: Seed to be set\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    import random\n",
        "\n",
        "    import numpy as np\n",
        "    import tensorflow as tf\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def train_sklearn_model(data_path: str, test_size: int, max_depth: int):\n",
        "    \"\"\"\n",
        "    A function to train a Decision Tree model using sklearn.\n",
        "    Args:\n",
        "        data_path: Path to the data\n",
        "        test_size: Size of the test set\n",
        "        max_depth: Maximum depth of the Decision Tree\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Libraries\n",
        "    import pandas as pd\n",
        "    from category_encoders import OrdinalEncoder\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "    # Read data\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(data_path)\n",
        "\n",
        "    # Train, test split\n",
        "    print(\"Generating train and test data...\")\n",
        "    x = df[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]]\n",
        "    y = df[[\"class\"]]\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        x, y, test_size=test_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Build pipeline\n",
        "    print(\"Building pipeline...\")\n",
        "    pipe = Pipeline(\n",
        "        [\n",
        "            (\"encoder\", OrdinalEncoder()),\n",
        "            (\"model\", DecisionTreeClassifier(criterion=\"gini\", max_depth=max_depth)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model...\")\n",
        "    pipe.fit(x_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"Evaluating model...\")\n",
        "    y_pred = pipe.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"accurancy\", round(accuracy, 3))\n",
        "\n",
        "\n",
        "def train_tensorflow_model(\n",
        "    data_path: str, test_size: float, batch_size: int, epochs: int\n",
        "):\n",
        "    \"\"\"\n",
        "    A function to train a TF model.\n",
        "    Args:\n",
        "        data_path: Path to the data\n",
        "        test_size: Size of the test set\n",
        "        batch_size: Batch size\n",
        "        epochs: Number of epochs\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Libraries\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Variables\n",
        "    dataset_size = 1729\n",
        "    features_values = {\n",
        "        \"buying\": [\"vhigh\", \"high\", \"med\", \"low\"],\n",
        "        \"maint\": [\"vhigh\", \"high\", \"med\", \"low\"],\n",
        "        \"doors\": [\"2\", \"3\", \"4\", \"5more\"],\n",
        "        \"persons\": [\"2\", \"4\", \"more\"],\n",
        "        \"lug_boot\": [\"small\", \"med\", \"big\"],\n",
        "        \"safety\": [\"low\", \"med\", \"high\"],\n",
        "    }\n",
        "\n",
        "    # Helpers\n",
        "    def get_input_layer(features_vocabulary):\n",
        "        input_map = {}\n",
        "        for cat_name, cat_values in features_vocabulary.items():\n",
        "            input_map[cat_name] = tf.keras.Input(\n",
        "                shape=(1,), name=cat_name, dtype=\"string\"\n",
        "            )\n",
        "        return input_map\n",
        "\n",
        "    def get_features_layer(inputs_map, features_vocabulary):\n",
        "        features_map = {}\n",
        "        for cat_name, cat_values in features_vocabulary.items():\n",
        "            # Calculate categories\n",
        "            cat_index = tf.keras.layers.StringLookup(\n",
        "                vocabulary=cat_values, max_tokens=5\n",
        "            )(inputs_map[cat_name])\n",
        "            # Create encoding layer\n",
        "            cat_layer = tf.keras.layers.CategoryEncoding(num_tokens=5)(cat_index)\n",
        "            features_map[cat_name] = cat_layer\n",
        "        return features_map\n",
        "\n",
        "    # Read data\n",
        "    print(\"Reading data...\")\n",
        "    car_dataset = tf.data.experimental.make_csv_dataset(\n",
        "        data_path,\n",
        "        column_names=[\n",
        "            \"buying\",\n",
        "            \"maint\",\n",
        "            \"doors\",\n",
        "            \"persons\",\n",
        "            \"lug_boot\",\n",
        "            \"safety\",\n",
        "            \"class\",\n",
        "        ],\n",
        "        label_name=\"class\",\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    # Generating Train, test split\n",
        "    print(\"Generating train and test data...\")\n",
        "    train_size = int(0.8 * dataset_size)\n",
        "    test_size = int(test_size * dataset_size)\n",
        "    train_dataset = car_dataset.take(train_size)\n",
        "    test_dataset = car_dataset.skip(train_size).take(test_size)\n",
        "\n",
        "    # Build model\n",
        "    print(\"Building model...\")\n",
        "    inputs_layer = get_input_layer(features_values)\n",
        "    features_layer = get_features_layer(inputs_layer, features_values)\n",
        "    x = tf.keras.layers.Concatenate()(features_layer.values())\n",
        "    x = tf.keras.layers.Dense(10, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(5, activation=\"relu\")(x)\n",
        "    output_layer = tf.keras.layers.Dense(1)(x)\n",
        "    model = tf.keras.Model(inputs=inputs_layer.values(), outputs=output_layer)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    # Fit the model\n",
        "    print(\"Training model...\")\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=test_dataset,\n",
        "    )\n",
        "\n",
        "def train_xgboost_model(data_path: str, test_size: int, max_depth: int, n_estimators: int,  enable_categorical: bool=True):\n",
        "    \"\"\"\n",
        "    A function to train an XGBoost model.\n",
        "    Args:\n",
        "        data_path: Path to the data\n",
        "        test_size: Size of the test set\n",
        "        max_depth: Maximum depth of the Decision Tree\n",
        "        n_estimators: Number of trees\n",
        "        enable_categorical: Whether to enable categorical features\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Libraries\n",
        "    import pandas as pd\n",
        "    from xgboost import XGBClassifier\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "    # Read data\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(data_path)\n",
        "\n",
        "    # Convert categorical columns to numerical values\n",
        "    for column in df.select_dtypes(include='object').columns:\n",
        "        label_encoder = LabelEncoder()\n",
        "        df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "    # Train, test split\n",
        "    print(\"Generating train and test data...\")\n",
        "    x = df[[\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]]\n",
        "    y = df[[\"class\"]]\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        x, y, test_size=test_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model...\")\n",
        "    clf = XGBClassifier(\n",
        "        max_depth=max_depth, n_estimators=n_estimators, objective=\"binary:logistic\"\n",
        "    )\n",
        "    clf.fit(x_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"Evaluating model...\")\n",
        "    y_pred = clf.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"accuracy\", round(accuracy, 3))\n",
        "\n",
        "\n",
        "def train_pytorch_model(\n",
        "    data_path: str, test_size: float, batch_size: int, lr: float, epochs: int, seed: int\n",
        "):\n",
        "\n",
        "    # Libraries\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torchmetrics\n",
        "    from torch.utils.data import DataLoader\n",
        "    from torchdata import datapipes\n",
        "\n",
        "    # Variables\n",
        "    seed = 8\n",
        "    features_map = {\n",
        "        0: {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
        "        1: {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
        "        2: {\"2\": 0, \"3\": 1, \"4\": 2, \"5more\": 3},\n",
        "        3: {\"2\": 0, \"4\": 1, \"more\": 2},\n",
        "        4: {\"small\": 0, \"med\": 1, \"big\": 2},\n",
        "        5: {\"low\": 0, \"med\": 1, \"high\": 2},\n",
        "    }\n",
        "    dataset_length = 1729\n",
        "\n",
        "    # Helpers\n",
        "    def row_processor(r):\n",
        "        for i, value in enumerate(r[:-1]):\n",
        "            r[i] = features_map[i][value]\n",
        "        return {\n",
        "            \"data\": np.array(r[:-1], dtype=np.float64),\n",
        "            \"labels\": np.array(r[-1], dtype=np.float64),\n",
        "        }\n",
        "\n",
        "    # Model definition\n",
        "    class SimpleNetwork(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.linear_relu = nn.Sequential(\n",
        "                nn.Linear(6, 12, dtype=torch.float64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(12, 6, dtype=torch.float64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(6, 3, dtype=torch.float64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(3, 1, dtype=torch.float64),\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            logits = self.linear_relu(x)\n",
        "            return logits\n",
        "\n",
        "    # Read data\n",
        "    print(\"Reading and preparing data...\")\n",
        "    read_dp = datapipes.iter.FileLister(data_path)\n",
        "    open_dp = datapipes.iter.FileOpener(read_dp)\n",
        "    parse_dp = datapipes.iter.CSVParser(open_dp, delimiter=\",\", skip_lines=1)\n",
        "    train_dp, test_dp = datapipes.iter.RandomSplitter(\n",
        "        parse_dp,\n",
        "        weights={\"train\": 1 - test_size, \"test\": test_size},\n",
        "        total_length=dataset_length,\n",
        "        seed=seed,\n",
        "    )\n",
        "    map_train_dp = datapipes.iter.Mapper(train_dp, row_processor)\n",
        "    map_test_dp = datapipes.iter.Mapper(test_dp, row_processor)\n",
        "    train_dataloader = DataLoader(map_train_dp, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(map_test_dp, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Build model\n",
        "    print(\"Building model...\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = SimpleNetwork().to(device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model...\")\n",
        "    model.train()\n",
        "    for t in range(epochs):\n",
        "        batch = 0\n",
        "        for row in iter(train_dataloader):\n",
        "            features, labels = row[\"data\"].to(device), row[\"labels\"].to(device)\n",
        "            train_predictions = model(features)\n",
        "            train_prediction, _ = torch.max(train_predictions, 1)\n",
        "            train_loss = loss_fn(train_prediction, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch += 1\n",
        "            print(f\"Epoch {t + 1} - Batch {batch} - Loss {train_loss.item():.4f}\")\n",
        "\n",
        "    # Test model\n",
        "    print(\"Evaluating model...\")\n",
        "    metric = torchmetrics.classification.BinaryAccuracy()\n",
        "    metric_values = []\n",
        "    model.eval()\n",
        "    for t in range(epochs):\n",
        "        batch = 0\n",
        "        with torch.no_grad():\n",
        "            for row in iter(test_dataloader):\n",
        "                features, labels = row[\"data\"].to(device), row[\"labels\"].to(device)\n",
        "                val_predictions = model(features)\n",
        "                val_prediction, _ = torch.max(val_predictions, 1)\n",
        "                metric.update(val_prediction, labels)\n",
        "        accuracy = metric.compute()\n",
        "        metric_values.append(accuracy)\n",
        "        metric.reset()\n",
        "\n",
        "        batch += 1\n",
        "        print(f\"Epoch {t + 1} - Batch {batch} - Accuracy {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python and set seed for reproducibility\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and set seed to guarantee reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G1l-7Wft3jb6"
      },
      "outputs": [],
      "source": [
        "vertex_ai.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n",
        "set_seed(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "004aGQ1BSLFm"
      },
      "source": [
        "## Model experimentation using autologging with Vertex AI Experiments\n",
        "\n",
        "Vertex AI Experiments Autologging allows you to run experiments and autologging parameters and metrics of different ML frameworks.\n",
        "\n",
        "After initiating an Vertex AI Experiment, enable autologging using `vertex_ai.autolog()`.\n",
        "\n",
        "There are two ways to use Autologging:\n",
        "\n",
        "1.   *With automatic experiment run creation*\n",
        "2.   *With user experiment run creation*\n",
        "\n",
        "With *automatic experiment run creation*, you run an experiment. Vertex AI SDK automatically creates an experiment run by logging all paramenters and metrics in Vertex AI Experiments.\n",
        "\n",
        "With *user experiment run creation*, you create an experiment using `vertex_ai.start_run(your-experiment-run-name)` and run the experiment. Then you get access to resulting paramentes and metrics after you end the experiment run with `vertex_ai.end_run()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjJVARe5V-MG"
      },
      "source": [
        "#### Create an experiment for tracking training parameters and metrics\n",
        "\n",
        "To start, initiate an experiment using the `init()` method.\n",
        "\n",
        "Because some model types like TensorFlow result in autologging time series metrics, you need to create a TensorBoard instance.\n",
        "\n",
        "To create a TensorBoard instance, you can use `vertex_ai.Tensorboard.create()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRoiPPk1XCWi"
      },
      "source": [
        "<div class=\"alert alert-danger\">Notice that if you did not activate yet, Vertex AI TensorBoard charges a monthly fee of $300 per unique active user. Learn more about [TensorBoard overview](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview). </div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r2z-VaIVTtI5"
      },
      "outputs": [],
      "source": [
        "autologged_experiment_name = f\"autologging-experiment-3modeltypes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eqM2pIO8_4Y7"
      },
      "outputs": [],
      "source": [
        "#experiment_tensorboard = vertex_ai.Tensorboard.create()\n",
        "vertex_ai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=BUCKET_URI,\n",
        "    experiment=autologged_experiment_name,\n",
        "#    experiment_tensorboard=experiment_tensorboard,\n",
        "    experiment_description=\"autolog-experiment-with-automatic-run\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCoYnaY594V7"
      },
      "source": [
        "#### Autologging an experiment with automatic experiment run creation\n",
        "\n",
        "In this section, Vertex AI SDK automatically creates an experiment run for you by logging all paramenters and training and post-training metrics in Vertex AI Experiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VGUnqk6Zvb6"
      },
      "source": [
        "##### Enable autologging\n",
        "\n",
        "First, enable autologging using `vertex_ai.autolog()` method.\n",
        "\n",
        "After calling `vertex_ai.autolog()`, any metrics and parameters from\n",
        "model training calls with supported ML frameworks will be automatically\n",
        "logged to Vertex Experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k0H9kw74-5ob"
      },
      "outputs": [],
      "source": [
        "vertex_ai.autolog()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWWr08gZZzMb"
      },
      "source": [
        "##### Run baseline experiment\n",
        "\n",
        "Next, define your baseline model by running a Sklearn model experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JCM9wLvRSaKc",
        "outputId": "d7f5e5c9-605b-4c56-e8dc-0d29f9c8338f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data...\n",
            "Generating train and test data...\n",
            "Building pipeline...\n",
            "Training model...\n",
            "Associating projects/903223461273/locations/europe-west4/metadataStores/default/contexts/autologging-experiment-3modeltypes-sklearn-2023-04-20-21-32-55-20aee to Experiment: autologging-experiment-3modeltypes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/903223461273/locations/europe-west4/metadataStores/default/contexts/autologging-experiment-3modeltypes-sklearn-2023-04-20-21-32-55-20aee to Experiment: autologging-experiment-3modeltypes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model...\n",
            "accurancy 0.934\n"
          ]
        }
      ],
      "source": [
        "sklearn_config = dict(data_path=processed_data_filepath, test_size=0.2, max_depth=5)\n",
        "train_sklearn_model(**sklearn_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQh3v_85aGWP"
      },
      "source": [
        "##### Get the experiment results\n",
        "\n",
        "Then, use the method `get_experiment_df()` to get the results of the experiment as a pandas dataframe.\n",
        "\n",
        "Notice how all paramenters and metrics are logged in Vertex AI Experiments.\n",
        "\n",
        "In particular, the `run_name` has been automatically assigned and the `accurancy_score` metrics you defined has been logged too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KuAl1etkLwAe",
        "outputId": "4aacbb2b-b888-4fe6-9bb6-63fc337b2d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                  0   \n",
              "experiment_name                  autologging-experiment-3modeltypes  \\\n",
              "run_name                          sklearn-2023-04-20-21-32-55-20aee   \n",
              "run_type                                       system.ExperimentRun   \n",
              "state                                                      COMPLETE   \n",
              "param.encoder__drop_invariant                                 False   \n",
              "...                                                             ...   \n",
              "metric.val_loss                                                 NaN   \n",
              "time_series_metric.loss                                         NaN   \n",
              "time_series_metric.val_accuracy                                 NaN   \n",
              "time_series_metric.val_loss                                     NaN   \n",
              "time_series_metric.accuracy                                     NaN   \n",
              "\n",
              "                                                                  1   \n",
              "experiment_name                  autologging-experiment-3modeltypes  \\\n",
              "run_name                          xgboost-2023-04-20-18-42-20-f4df0   \n",
              "run_type                                       system.ExperimentRun   \n",
              "state                                                      COMPLETE   \n",
              "param.encoder__drop_invariant                                   NaN   \n",
              "...                                                             ...   \n",
              "metric.val_loss                                                 NaN   \n",
              "time_series_metric.loss                                         NaN   \n",
              "time_series_metric.val_accuracy                                 NaN   \n",
              "time_series_metric.val_loss                                     NaN   \n",
              "time_series_metric.accuracy                                     NaN   \n",
              "\n",
              "                                                                    2   \n",
              "experiment_name                    autologging-experiment-3modeltypes  \\\n",
              "run_name                         tensorflow-2023-04-20-17-40-17-5becd   \n",
              "run_type                                         system.ExperimentRun   \n",
              "state                                                        COMPLETE   \n",
              "param.encoder__drop_invariant                                     NaN   \n",
              "...                                                               ...   \n",
              "metric.val_loss                                              1.198227   \n",
              "time_series_metric.loss                                      1.197857   \n",
              "time_series_metric.val_accuracy                              0.922319   \n",
              "time_series_metric.val_loss                                  1.198227   \n",
              "time_series_metric.accuracy                                  0.922343   \n",
              "\n",
              "                                                                  3  \n",
              "experiment_name                  autologging-experiment-3modeltypes  \n",
              "run_name                          sklearn-2023-04-20-17-39-46-f4bb4  \n",
              "run_type                                       system.ExperimentRun  \n",
              "state                                                      COMPLETE  \n",
              "param.encoder__drop_invariant                                 False  \n",
              "...                                                             ...  \n",
              "metric.val_loss                                                 NaN  \n",
              "time_series_metric.loss                                         NaN  \n",
              "time_series_metric.val_accuracy                                 NaN  \n",
              "time_series_metric.val_loss                                     NaN  \n",
              "time_series_metric.accuracy                                     NaN  \n",
              "\n",
              "[110 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-656f3fa5-8e59-4d68-83e5-823646b66926\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>experiment_name</th>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>run_name</th>\n",
              "      <td>sklearn-2023-04-20-21-32-55-20aee</td>\n",
              "      <td>xgboost-2023-04-20-18-42-20-f4df0</td>\n",
              "      <td>tensorflow-2023-04-20-17-40-17-5becd</td>\n",
              "      <td>sklearn-2023-04-20-17-39-46-f4bb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>run_type</th>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param.encoder__drop_invariant</th>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric.val_loss</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.198227</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.loss</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.197857</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.val_accuracy</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.922319</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.val_loss</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.198227</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.accuracy</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.922343</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>110 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-656f3fa5-8e59-4d68-83e5-823646b66926')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-656f3fa5-8e59-4d68-83e5-823646b66926 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-656f3fa5-8e59-4d68-83e5-823646b66926');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "experiment_df = vertex_ai.get_experiment_df()\n",
        "experiment_df = experiment_df.T\n",
        "experiment_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 1 - XGBoost model\n",
        "\n",
        "Preprocess: XGBoost can only work with data types of int, float, bool, or category. The columns buying, maint, doors, persons, lug_boot, and safety are all of type object, which is not compatible with XGBoost. \n",
        "\n",
        "To fix this, let's convert the data types of these columns to one of the compatible types. We can do this using the pandas.DataFrame.astype() method:\n",
        "\n"
      ],
      "metadata": {
        "id": "mFcmm9y107Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_config = dict(data_path=processed_data_filepath, test_size=0.2, max_depth=10, n_estimators=200)\n",
        "train_xgboost_model(**xgboost_config)"
      ],
      "metadata": {
        "id": "NSladWsI04jh",
        "outputId": "0ea66899-bb4e-4811-af88-c8c9191895f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data...\n",
            "Generating train and test data...\n",
            "Training model...\n",
            "Associating projects/903223461273/locations/europe-west4/metadataStores/default/contexts/autologging-experiment-3modeltypes-xgboost-2023-04-20-21-36-44-c2144 to Experiment: autologging-experiment-3modeltypes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/903223461273/locations/europe-west4/metadataStores/default/contexts/autologging-experiment-3modeltypes-xgboost-2023-04-20-21-36-44-c2144 to Experiment: autologging-experiment-3modeltypes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model...\n",
            "accuracy 0.986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQlwVV_VMjGZ"
      },
      "source": [
        "#### Experiment 2 - TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qOu7DxpVVMMY",
        "outputId": "0d23d1eb-bad3-4d45-e941-2e0319267cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data...\n",
            "Generating train and test data...\n",
            "Building model...\n",
            "Training model...\n",
            "Associating projects/903223461273/locations/europe-west4/metadataStores/default/contexts/autologging-experiment-3modeltypes-tensorflow-2023-04-20-21-33-50-eb9c9 to Experiment: autologging-experiment-3modeltypes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/903223461273/locations/europe-west4/metadataStores/default/contexts/autologging-experiment-3modeltypes-tensorflow-2023-04-20-21-33-50-eb9c9 to Experiment: autologging-experiment-3modeltypes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "   6/1383 [..............................] - ETA: 17s - loss: 1.5425 - accuracy: 0.9000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_train_batch_end` time: 0.0290s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1383/1383 [==============================] - 16s 9ms/step - loss: 1.1979 - accuracy: 0.9223 - val_loss: 1.1982 - val_accuracy: 0.9223\n",
            "Epoch 2/3\n",
            "1383/1383 [==============================] - 17s 12ms/step - loss: 1.1956 - accuracy: 0.9225 - val_loss: 1.1893 - val_accuracy: 0.9229\n",
            "Epoch 3/3\n",
            "1383/1383 [==============================] - 10s 7ms/step - loss: 1.1979 - accuracy: 0.9223 - val_loss: 1.1982 - val_accuracy: 0.9223\n"
          ]
        }
      ],
      "source": [
        "tf_config = dict(\n",
        "    data_path=processed_data_filepath, test_size=0.2, batch_size=5, epochs=3\n",
        ")\n",
        "train_tensorflow_model(**tf_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAQUlys2j0UN"
      },
      "source": [
        "##### Compare experiment results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2XcCQUCgdTmG",
        "outputId": "b4dcdf7a-ebc2-4492-d9b5-b304b843d10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                    0   \n",
              "experiment_name                    autologging-experiment-3modeltypes  \\\n",
              "run_name                         tensorflow-2023-04-20-21-33-50-eb9c9   \n",
              "run_type                                         system.ExperimentRun   \n",
              "state                                                        COMPLETE   \n",
              "param.epochs                                                        3   \n",
              "...                                                               ...   \n",
              "metric.training_roc_auc                                           NaN   \n",
              "time_series_metric.loss                                      1.197857   \n",
              "time_series_metric.val_accuracy                              0.922319   \n",
              "time_series_metric.val_loss                                  1.198227   \n",
              "time_series_metric.accuracy                                  0.922343   \n",
              "\n",
              "                                                                  1   \n",
              "experiment_name                  autologging-experiment-3modeltypes  \\\n",
              "run_name                          xgboost-2023-04-20-21-33-34-86379   \n",
              "run_type                                       system.ExperimentRun   \n",
              "state                                                      COMPLETE   \n",
              "param.epochs                                                    NaN   \n",
              "...                                                             ...   \n",
              "metric.training_roc_auc                                         NaN   \n",
              "time_series_metric.loss                                         NaN   \n",
              "time_series_metric.val_accuracy                                 NaN   \n",
              "time_series_metric.val_loss                                     NaN   \n",
              "time_series_metric.accuracy                                     NaN   \n",
              "\n",
              "                                                                  2   \n",
              "experiment_name                  autologging-experiment-3modeltypes  \\\n",
              "run_name                          sklearn-2023-04-20-21-32-55-20aee   \n",
              "run_type                                       system.ExperimentRun   \n",
              "state                                                      COMPLETE   \n",
              "param.epochs                                                    NaN   \n",
              "...                                                             ...   \n",
              "metric.training_roc_auc                                    0.977436   \n",
              "time_series_metric.loss                                         NaN   \n",
              "time_series_metric.val_accuracy                                 NaN   \n",
              "time_series_metric.val_loss                                     NaN   \n",
              "time_series_metric.accuracy                                     NaN   \n",
              "\n",
              "                                                                  3   \n",
              "experiment_name                  autologging-experiment-3modeltypes  \\\n",
              "run_name                          xgboost-2023-04-20-18-42-20-f4df0   \n",
              "run_type                                       system.ExperimentRun   \n",
              "state                                                      COMPLETE   \n",
              "param.epochs                                                    NaN   \n",
              "...                                                             ...   \n",
              "metric.training_roc_auc                                         NaN   \n",
              "time_series_metric.loss                                         NaN   \n",
              "time_series_metric.val_accuracy                                 NaN   \n",
              "time_series_metric.val_loss                                     NaN   \n",
              "time_series_metric.accuracy                                     NaN   \n",
              "\n",
              "                                                                    4   \n",
              "experiment_name                    autologging-experiment-3modeltypes  \\\n",
              "run_name                         tensorflow-2023-04-20-17-40-17-5becd   \n",
              "run_type                                         system.ExperimentRun   \n",
              "state                                                        COMPLETE   \n",
              "param.epochs                                                        3   \n",
              "...                                                               ...   \n",
              "metric.training_roc_auc                                           NaN   \n",
              "time_series_metric.loss                                      1.197857   \n",
              "time_series_metric.val_accuracy                              0.922319   \n",
              "time_series_metric.val_loss                                  1.198227   \n",
              "time_series_metric.accuracy                                  0.922343   \n",
              "\n",
              "                                                                  5  \n",
              "experiment_name                  autologging-experiment-3modeltypes  \n",
              "run_name                          sklearn-2023-04-20-17-39-46-f4bb4  \n",
              "run_type                                       system.ExperimentRun  \n",
              "state                                                      COMPLETE  \n",
              "param.epochs                                                    NaN  \n",
              "...                                                             ...  \n",
              "metric.training_roc_auc                                    0.977436  \n",
              "time_series_metric.loss                                         NaN  \n",
              "time_series_metric.val_accuracy                                 NaN  \n",
              "time_series_metric.val_loss                                     NaN  \n",
              "time_series_metric.accuracy                                     NaN  \n",
              "\n",
              "[110 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cf46ca6-21f8-44fc-acc4-898e558130c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>experiment_name</th>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "      <td>autologging-experiment-3modeltypes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>run_name</th>\n",
              "      <td>tensorflow-2023-04-20-21-33-50-eb9c9</td>\n",
              "      <td>xgboost-2023-04-20-21-33-34-86379</td>\n",
              "      <td>sklearn-2023-04-20-21-32-55-20aee</td>\n",
              "      <td>xgboost-2023-04-20-18-42-20-f4df0</td>\n",
              "      <td>tensorflow-2023-04-20-17-40-17-5becd</td>\n",
              "      <td>sklearn-2023-04-20-17-39-46-f4bb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>run_type</th>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "      <td>system.ExperimentRun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param.epochs</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric.training_roc_auc</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.977436</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.977436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.loss</th>\n",
              "      <td>1.197857</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.197857</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.val_accuracy</th>\n",
              "      <td>0.922319</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.922319</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.val_loss</th>\n",
              "      <td>1.198227</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.198227</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_series_metric.accuracy</th>\n",
              "      <td>0.922343</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.922343</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>110 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cf46ca6-21f8-44fc-acc4-898e558130c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cf46ca6-21f8-44fc-acc4-898e558130c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cf46ca6-21f8-44fc-acc4-898e558130c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "experiment_df = vertex_ai.get_experiment_df()\n",
        "experiment_df.T"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "get_started_with_vertex_experiments_autologging.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}